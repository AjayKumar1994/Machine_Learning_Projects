{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import datetime\n",
    "#import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/08/17</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>While I was informed by XXXX my credit score w...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>NC</td>\n",
       "      <td>285XX</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/08/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2378505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/28/17</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Federal student loan servicing</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Problem with personal statement of dispute</td>\n",
       "      <td>Navient was supposed to send me documents regu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, LLC.</td>\n",
       "      <td>MO</td>\n",
       "      <td>63301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>07/28/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2589070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/26/17</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Improper use of my credit report</td>\n",
       "      <td>Report improperly shared by CRC</td>\n",
       "      <td>XXXX XXXX, DE XXXX ( XXXX ) XXXX Requested On ...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>DE</td>\n",
       "      <td>197XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/26/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2404036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/10/17</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>VA mortgage</td>\n",
       "      <td>Struggling to pay mortgage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We live in an area that was affected by Hurric...</td>\n",
       "      <td>Company believes it acted appropriately as aut...</td>\n",
       "      <td>Pacific Union Financial, LLC</td>\n",
       "      <td>TX</td>\n",
       "      <td>77469</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>11/10/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2724813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/27/17</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Billing disputes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello team, I need your help. Please can you a...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/02/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2362090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received           Product                     Sub-product  \\\n",
       "0      03/08/17  Credit reporting                             NaN   \n",
       "1      07/28/17      Student loan  Federal student loan servicing   \n",
       "2      03/26/17  Credit reporting                             NaN   \n",
       "3      11/10/17          Mortgage                     VA mortgage   \n",
       "4      02/27/17       Credit card                             NaN   \n",
       "\n",
       "                                               Issue  \\\n",
       "0             Incorrect information on credit report   \n",
       "1  Problem with a credit reporting company's inve...   \n",
       "2                   Improper use of my credit report   \n",
       "3                         Struggling to pay mortgage   \n",
       "4                                   Billing disputes   \n",
       "\n",
       "                                    Sub-issue  \\\n",
       "0                              Account status   \n",
       "1  Problem with personal statement of dispute   \n",
       "2             Report improperly shared by CRC   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0  While I was informed by XXXX my credit score w...   \n",
       "1  Navient was supposed to send me documents regu...   \n",
       "2  XXXX XXXX, DE XXXX ( XXXX ) XXXX Requested On ...   \n",
       "3  We live in an area that was affected by Hurric...   \n",
       "4  Hello team, I need your help. Please can you a...   \n",
       "\n",
       "                             Company public response  \\\n",
       "0  Company has responded to the consumer and the ...   \n",
       "1                                                NaN   \n",
       "2  Company has responded to the consumer and the ...   \n",
       "3  Company believes it acted appropriately as aut...   \n",
       "4  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                  Company State ZIP code            Tags  \\\n",
       "0  TRANSUNION INTERMEDIATE HOLDINGS, INC.    NC    285XX  Older American   \n",
       "1                 Navient Solutions, LLC.    MO    63301             NaN   \n",
       "2  TRANSUNION INTERMEDIATE HOLDINGS, INC.    DE    197XX             NaN   \n",
       "3            Pacific Union Financial, LLC    TX    77469   Servicemember   \n",
       "4                          CITIBANK, N.A.   NaN      NaN  Older American   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0           Consent provided           Web             03/08/17   \n",
       "1           Consent provided           Web             07/28/17   \n",
       "2           Consent provided           Web             03/26/17   \n",
       "3           Consent provided           Web             11/10/17   \n",
       "4           Consent provided           Web             03/02/17   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                 No   \n",
       "1      Closed with explanation              Yes                NaN   \n",
       "2      Closed with explanation              Yes                 No   \n",
       "3      Closed with explanation               No                NaN   \n",
       "4      Closed with explanation              Yes                 No   \n",
       "\n",
       "   Complaint ID  \n",
       "0       2378505  \n",
       "1       2589070  \n",
       "2       2404036  \n",
       "3       2724813  \n",
       "4       2362090  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit reporting, credit repair services, or other personal consumer reports    37463\n",
       "Debt collection                                                                 24288\n",
       "Mortgage                                                                        13436\n",
       "Student loan                                                                     9831\n",
       "Credit card or prepaid card                                                      8136\n",
       "Credit reporting                                                                 6265\n",
       "Checking or savings account                                                      4946\n",
       "Credit card                                                                      3176\n",
       "Bank account or service                                                          2576\n",
       "Money transfer, virtual currency, or money service                               2174\n",
       "Vehicle loan or lease                                                            2136\n",
       "Consumer Loan                                                                    1831\n",
       "Payday loan, title loan, or personal loan                                        1711\n",
       "Payday loan                                                                       268\n",
       "Money transfers                                                                   224\n",
       "Prepaid card                                                                      186\n",
       "Other financial service                                                            66\n",
       "Virtual currency                                                                    3\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subproduct - Student Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = data.loc[data.Product == 'Student loan' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/28/17</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Federal student loan servicing</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Problem with personal statement of dispute</td>\n",
       "      <td>Navient was supposed to send me documents regu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, LLC.</td>\n",
       "      <td>MO</td>\n",
       "      <td>63301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>07/28/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2589070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01/18/17</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Federal student loan servicing</td>\n",
       "      <td>Can't repay my loan</td>\n",
       "      <td>Can't decrease my monthly payments</td>\n",
       "      <td>I 've been working with Navient Loans for over...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, LLC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>312XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01/18/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2295191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>02/22/17</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Federal student loan servicing</td>\n",
       "      <td>Dealing with my lender or servicer</td>\n",
       "      <td>Trouble with how payments are handled</td>\n",
       "      <td>Fedloans.org does not process payments in a ti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AES/PHEAA</td>\n",
       "      <td>CA</td>\n",
       "      <td>950XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>02/27/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2353979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>01/23/17</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Non-federal student loan</td>\n",
       "      <td>Dealing with my lender or servicer</td>\n",
       "      <td>Trouble with how payments are handled</td>\n",
       "      <td>I had gotten a loan from XXXX XXXX around XXXX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, LLC.</td>\n",
       "      <td>CA</td>\n",
       "      <td>920XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01/23/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2306568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>01/26/17</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Non-federal student loan</td>\n",
       "      <td>Can't repay my loan</td>\n",
       "      <td>Can't decrease my monthly payments</td>\n",
       "      <td>I tried to refinance my student loans. Being t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, LLC.</td>\n",
       "      <td>NY</td>\n",
       "      <td>112XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01/26/17</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2313928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date received       Product                     Sub-product  \\\n",
       "1       07/28/17  Student loan  Federal student loan servicing   \n",
       "6       01/18/17  Student loan  Federal student loan servicing   \n",
       "32      02/22/17  Student loan  Federal student loan servicing   \n",
       "36      01/23/17  Student loan        Non-federal student loan   \n",
       "42      01/26/17  Student loan        Non-federal student loan   \n",
       "\n",
       "                                                Issue  \\\n",
       "1   Problem with a credit reporting company's inve...   \n",
       "6                                 Can't repay my loan   \n",
       "32                 Dealing with my lender or servicer   \n",
       "36                 Dealing with my lender or servicer   \n",
       "42                                Can't repay my loan   \n",
       "\n",
       "                                     Sub-issue  \\\n",
       "1   Problem with personal statement of dispute   \n",
       "6           Can't decrease my monthly payments   \n",
       "32       Trouble with how payments are handled   \n",
       "36       Trouble with how payments are handled   \n",
       "42          Can't decrease my monthly payments   \n",
       "\n",
       "                         Consumer complaint narrative Company public response  \\\n",
       "1   Navient was supposed to send me documents regu...                     NaN   \n",
       "6   I 've been working with Navient Loans for over...                     NaN   \n",
       "32  Fedloans.org does not process payments in a ti...                     NaN   \n",
       "36  I had gotten a loan from XXXX XXXX around XXXX...                     NaN   \n",
       "42  I tried to refinance my student loans. Being t...                     NaN   \n",
       "\n",
       "                    Company State ZIP code Tags Consumer consent provided?  \\\n",
       "1   Navient Solutions, LLC.    MO    63301  NaN           Consent provided   \n",
       "6   Navient Solutions, LLC.    GA    312XX  NaN           Consent provided   \n",
       "32                AES/PHEAA    CA    950XX  NaN           Consent provided   \n",
       "36  Navient Solutions, LLC.    CA    920XX  NaN           Consent provided   \n",
       "42  Navient Solutions, LLC.    NY    112XX  NaN           Consent provided   \n",
       "\n",
       "   Submitted via Date sent to company Company response to consumer  \\\n",
       "1            Web             07/28/17      Closed with explanation   \n",
       "6            Web             01/18/17      Closed with explanation   \n",
       "32           Web             02/27/17      Closed with explanation   \n",
       "36           Web             01/23/17      Closed with explanation   \n",
       "42           Web             01/26/17      Closed with explanation   \n",
       "\n",
       "   Timely response? Consumer disputed?  Complaint ID  \n",
       "1               Yes                NaN       2589070  \n",
       "6               Yes                Yes       2295191  \n",
       "32              Yes                 No       2353979  \n",
       "36              Yes                 No       2306568  \n",
       "42              Yes                 No       2313928  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count across categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Federal student loan servicing    6177\n",
       "Non-federal student loan          1901\n",
       "Private student loan              1753\n",
       "Name: Sub-product, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf['Sub-product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Navient was supposed to send me documents regu...\n",
       "6     I 've been working with Navient Loans for over...\n",
       "32    Fedloans.org does not process payments in a ti...\n",
       "36    I had gotten a loan from XXXX XXXX around XXXX...\n",
       "42    I tried to refinance my student loans. Being t...\n",
       "Name: Consumer complaint narrative, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf['Consumer complaint narrative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf = tf[['Sub-product','Consumer complaint narrative']]\n",
    "tf1 = tf[['Consumer complaint narrative']]\n",
    "tf2 = tf[['Sub-product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Navient was supposed to send me documents regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I 've been working with Navient Loans for over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fedloans.org does not process payments in a ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I had gotten a loan from XXXX XXXX around XXXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I tried to refinance my student loans. Being t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Consumer complaint narrative\n",
       "1   Navient was supposed to send me documents regu...\n",
       "6   I 've been working with Navient Loans for over...\n",
       "32  Fedloans.org does not process payments in a ti...\n",
       "36  I had gotten a loan from XXXX XXXX around XXXX...\n",
       "42  I tried to refinance my student loans. Being t..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test = data.loc[data.Product == 'Student loan' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_test['Sub-product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_test['Consumer complaint narrative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test1 = tf_test[['Consumer complaint narrative']]\n",
    "tf_test2 = tf_test[['Sub-product']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
    "stemmer=SnowballStemmer('english')\n",
    "lemma=WordNetLemmatizer()\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review_col):\n",
    "    review_corpus=[]\n",
    "    for i in range(0,len(review_col)):\n",
    "        review=str(review_col[i])\n",
    "        review=re.sub('[^a-zA-Z]',' ',review)\n",
    "        \n",
    "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
    "        review=' '.join(review)\n",
    "        review_corpus.append(review)\n",
    "    return review_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tf1['clean_review']=clean_review(tf1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tf_test1['clean_review']=clean_review(tf_test1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Navient was supposed to send me documents regu...</td>\n",
       "      <td>navient wa supposed to send me document reguar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I 've been working with Navient Loans for over...</td>\n",
       "      <td>i ve been working with navient loan for over a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fedloans.org does not process payments in a ti...</td>\n",
       "      <td>fedloans org doe not process payment in a time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I had gotten a loan from XXXX XXXX around XXXX...</td>\n",
       "      <td>i had gotten a loan from xxxx xxxx around xxxx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I tried to refinance my student loans. Being t...</td>\n",
       "      <td>i tried to refinance my student loan being tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Consumer complaint narrative  \\\n",
       "1   Navient was supposed to send me documents regu...   \n",
       "6   I 've been working with Navient Loans for over...   \n",
       "32  Fedloans.org does not process payments in a ti...   \n",
       "36  I had gotten a loan from XXXX XXXX around XXXX...   \n",
       "42  I tried to refinance my student loans. Being t...   \n",
       "\n",
       "                                         clean_review  \n",
       "1   navient wa supposed to send me document reguar...  \n",
       "6   i ve been working with navient loan for over a...  \n",
       "32  fedloans org doe not process payment in a time...  \n",
       "36  i had gotten a loan from xxxx xxxx around xxxx...  \n",
       "42  i tried to refinance my student loan being tha...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Navient was supposed to send me documents regu...</td>\n",
       "      <td>navient wa supposed to send me document reguar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I 've been working with Navient Loans for over...</td>\n",
       "      <td>i ve been working with navient loan for over a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fedloans.org does not process payments in a ti...</td>\n",
       "      <td>fedloans org doe not process payment in a time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I had gotten a loan from XXXX XXXX around XXXX...</td>\n",
       "      <td>i had gotten a loan from xxxx xxxx around xxxx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I tried to refinance my student loans. Being t...</td>\n",
       "      <td>i tried to refinance my student loan being tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Consumer complaint narrative  \\\n",
       "1   Navient was supposed to send me documents regu...   \n",
       "6   I 've been working with Navient Loans for over...   \n",
       "32  Fedloans.org does not process payments in a ti...   \n",
       "36  I had gotten a loan from XXXX XXXX around XXXX...   \n",
       "42  I tried to refinance my student loans. Being t...   \n",
       "\n",
       "                                         clean_review  \n",
       "1   navient wa supposed to send me document reguar...  \n",
       "6   i ve been working with navient loan for over a...  \n",
       "32  fedloans org doe not process payment in a time...  \n",
       "36  i had gotten a loan from xxxx xxxx around xxxx...  \n",
       "42  i tried to refinance my student loan being tha...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub-product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Federal student loan servicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Federal student loan servicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Federal student loan servicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Non-federal student loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Non-federal student loan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Sub-product\n",
       "1   Federal student loan servicing\n",
       "6   Federal student loan servicing\n",
       "32  Federal student loan servicing\n",
       "36        Non-federal student loan\n",
       "42        Non-federal student loan"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf1['clean_review']\n",
    "#print(X)\n",
    "Y = tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf_test1['clean_review']\n",
    "#print(X)\n",
    "Y_test = tf_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n",
    "vectorizer.fit(X)\n",
    "X_vectorized = vectorizer.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "ovr = OneVsRestClassifier(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 83.9 ms, total: 4.78 s\n",
      "Wall time: 3.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ovr.fit(X_vectorized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy 68.44%, std 0.39.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = cross_val_score(ovr,X_vectorized,Y, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy 62.83%, std 0.02.\n",
      "CPU times: user 418 ms, sys: 121 ms, total: 539 ms\n",
      "Wall time: 986 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = MultinomialNB()\n",
    "#model.fit(train_vectorized, y)\n",
    "scores =  cross_val_score(model, X_vectorized,Y, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16119"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words=' '.join(X)\n",
    "all_words=word_tokenize(all_words)\n",
    "#print(all_words)\n",
    "dist=FreqDist(all_words)\n",
    "\n",
    "num_unique_word=len(dist)\n",
    "num_unique_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_unique_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokens = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and truncating data\n",
    "The Recurrent Neural Network can take sequences of arbitrary length as input, but in order to use a whole batch of data, the sequences need to have the same length. But if we take the longest sentence we waste a lot of memory. So, we truncate longer sentences and pad shorter sentences.\n",
    "\n",
    "First we count the number of tokens in all the sequences in the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens ]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of tokens in a sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.07232224595666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum number of tokens in a sequence is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3221"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max number of tokens we will allow is set to the average plus 2 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This covers about 95% of the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546333028176177"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When padding or truncating the sequences that have a different length, we need to determine if we want to do this padding or truncating 'pre' or 'post'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9831, 642)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9831, 642)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,  186,   33,  270,   23,   26,    8,   16,   73,    7,   36,\n",
       "         62,  187,    2,   49,   91,    5,   81,  414,   13,   78,   14,\n",
       "         15,  237,    1,  455,   47,  165,   68,  777,   31,    5,  266,\n",
       "         79,    2,   38,    1,  186,  987,   74,  685,    5,  717,   56,\n",
       "          4,  237,  259,    2,  780,    6,  151,    5,   81,  901,    7,\n",
       "         10,  185,  231,   14,  285,    2,  286,   14,   45,   20,  454,\n",
       "          4,   79,   62,   14,   45,   20,  626,    2,  132,   23,   19,\n",
       "          5,    1,   65,   20,  182,    4,   13,    5,   21,   22, 1249,\n",
       "          6,   60,    5,   14,   45,  915,    2, 1169,    6,  317,    5,\n",
       "        220])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    1,  186,   33,  270,   23,   26,    8,   16,\n",
       "         73,    7,   36,   62,  187,    2,   49,   91,    5,   81,  414,\n",
       "         13,   78,   14,   15,  237,    1,  455,   47,  165,   68,  777,\n",
       "         31,    5,  266,   79,    2,   38,    1,  186,  987,   74,  685,\n",
       "          5,  717,   56,    4,  237,  259,    2,  780,    6,  151,    5,\n",
       "         81,  901,    7,   10,  185,  231,   14,  285,    2,  286,   14,\n",
       "         45,   20,  454,    4,   79,   62,   14,   45,   20,  626,    2,\n",
       "        132,   23,   19,    5,    1,   65,   20,  182,    4,   13,    5,\n",
       "         21,   22, 1249,    6,   60,    5,   14,   45,  915,    2, 1169,\n",
       "          6,  317,    5,  220], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "values = array(Y)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(Y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "values_0 = array(Y_test)\n",
    "#print(values)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values_0)\n",
    "#print(integer_encoded)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_encoded_test = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(Y_encoded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOVE\n",
    "We would use pretrained embedding 'GLOVE', which is pretrained using billions of words, which could improve our accuracy compared to training our own embedding. Embeddings generally represent geometrical encodings of words based on how frequently appear together in a text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'glove.6B.100d.txt'\n",
    "embeddings_index = dict()\n",
    "\n",
    "            #Transfer the embedding weights into a dictionary by iterating through every line of the file.\n",
    "f = open(filename)\n",
    "for line in f:\n",
    "                #split up line into an indexed array\n",
    "    values = line.split()\n",
    "   # print(values)\n",
    "                #first index is word\n",
    "    word = values[0]\n",
    "                #store the rest of the values in the array as a new array\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    #print(coefs)\n",
    "    embeddings_index[word] = coefs #100 dimensions\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "  \n",
    "        #We get the mean and standard deviation of the embedding weights so that we could maintain the \n",
    "        #same statistics for the rest of our own random generated weights. \n",
    "all_embs = np.stack(list(embeddings_index.values()))\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        \n",
    "   \n",
    "        #We are going to set the embedding size to the pretrained dimension as we are replicating it.\n",
    "        #the size will be Number of Words in Vocab X Embedding Size\n",
    "embed_size = 100\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (num_unique_word, embed_size))\n",
    "\n",
    "   \n",
    "        #With the newly created embedding matrix, we'll fill it up with the words \n",
    "        #that we have in both \n",
    "        #our own dictionary and loaded pretrained embedding. \n",
    "embeddedCount = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "     \n",
    "            #then we see if this word is in glove's dictionary, if yes, get the corresponding weights\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "   \n",
    "            #and store inside the embedding matrix that we will train later on.\n",
    "        if embedding_vector is not None: \n",
    "             embedding_matrix[i-1] = embedding_vector\n",
    "        embeddedCount+=1\n",
    "    #print(embeddedCount)\n",
    "    #print('total embedded:',embeddedCount,'common words')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.046539  ,  0.61966002,  0.56647003, ..., -0.37616   ,\n",
       "        -0.032502  ,  0.80620003],\n",
       "       [-0.18970001,  0.050024  ,  0.19084001, ..., -0.39804   ,\n",
       "         0.47646999, -0.15983   ],\n",
       "       [-0.1429    ,  1.06210005,  0.82244998, ...,  0.19328   ,\n",
       "        -0.20184   ,  0.91416001],\n",
       "       ...,\n",
       "       [-0.31443228,  0.08975162,  0.39416614, ..., -0.25870429,\n",
       "         0.18590435, -0.10240769],\n",
       "       [-0.09377324,  0.01066256, -0.11949073, ..., -0.09724542,\n",
       "        -0.10935151,  0.19399601],\n",
       "       [ 0.22801   ,  0.77542001, -0.038877  , ...,  0.22254001,\n",
       "         0.16836999,  0.48008999]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16119, 100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding matrix from pretrained model would be used as embedding for the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_tokens, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Embedding(len(tokenizer.word_index), embedding_matrix.shape[1],weights=[embedding_matrix],trainable=False)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(LSTM(60, return_sequences=True,name='lstm_layer',dropout=0.1,recurrent_dropout=0.1))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(50, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(3, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 642)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 642, 100)          1611900   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 642, 120)          77280     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,695,383\n",
      "Trainable params: 83,483\n",
      "Non-trainable params: 1,611,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8847 samples, validate on 984 samples\n",
      "Epoch 1/10\n",
      "8847/8847 [==============================] - 214s 24ms/step - loss: 0.7315 - acc: 0.7001 - val_loss: 0.7567 - val_acc: 0.6819\n",
      "Epoch 2/10\n",
      "8847/8847 [==============================] - 215s 24ms/step - loss: 0.7003 - acc: 0.7103 - val_loss: 0.7469 - val_acc: 0.6839\n",
      "Epoch 3/10\n",
      "8847/8847 [==============================] - 217s 24ms/step - loss: 0.6906 - acc: 0.7129 - val_loss: 0.7533 - val_acc: 0.6850\n",
      "Epoch 4/10\n",
      "8847/8847 [==============================] - 215s 24ms/step - loss: 0.6627 - acc: 0.7222 - val_loss: 0.7379 - val_acc: 0.6911\n",
      "Epoch 5/10\n",
      "8847/8847 [==============================] - 214s 24ms/step - loss: 0.6466 - acc: 0.7332 - val_loss: 0.7806 - val_acc: 0.6982\n",
      "Epoch 6/10\n",
      "8847/8847 [==============================] - 214s 24ms/step - loss: 0.6270 - acc: 0.7390 - val_loss: 0.7411 - val_acc: 0.6890\n",
      "Epoch 7/10\n",
      "8847/8847 [==============================] - 216s 24ms/step - loss: 0.6064 - acc: 0.7547 - val_loss: 0.7417 - val_acc: 0.6900\n",
      "Epoch 8/10\n",
      "8847/8847 [==============================] - 216s 24ms/step - loss: 0.5815 - acc: 0.7601 - val_loss: 0.7625 - val_acc: 0.6961\n",
      "Epoch 9/10\n",
      "8847/8847 [==============================] - 216s 24ms/step - loss: 0.5567 - acc: 0.7692 - val_loss: 0.7643 - val_acc: 0.7063\n",
      "Epoch 10/10\n",
      "8847/8847 [==============================] - 215s 24ms/step - loss: 0.5352 - acc: 0.7809 - val_loss: 0.7874 - val_acc: 0.6961\n",
      "CPU times: user 2h 2min 4s, sys: 13min 36s, total: 2h 15min 40s\n",
      "Wall time: 35min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x_train_pad, Y_encoded, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9831/9831 [==============================] - 58s 6ms/step\n",
      "CPU times: user 3min 19s, sys: 16.3 s, total: 3min 36s\n",
      "Wall time: 58.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model.evaluate(x_test_pad, Y_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.11%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_tokens, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "x = Embedding(num_unique_word, embed_size)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = GlobalMaxPool1D()(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(50, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(3, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8847 samples, validate on 984 samples\n",
      "Epoch 1/10\n",
      "8847/8847 [==============================] - 125s 14ms/step - loss: 0.9286 - acc: 0.6234 - val_loss: 0.8879 - val_acc: 0.6209\n",
      "Epoch 2/10\n",
      "8847/8847 [==============================] - 127s 14ms/step - loss: 0.7585 - acc: 0.6834 - val_loss: 0.6984 - val_acc: 0.7043\n",
      "Epoch 3/10\n",
      "8847/8847 [==============================] - 127s 14ms/step - loss: 0.6398 - acc: 0.7389 - val_loss: 0.7046 - val_acc: 0.6931\n",
      "Epoch 4/10\n",
      "8847/8847 [==============================] - 128s 14ms/step - loss: 0.5484 - acc: 0.7780 - val_loss: 0.7295 - val_acc: 0.6921\n",
      "Epoch 5/10\n",
      "8847/8847 [==============================] - 128s 14ms/step - loss: 0.4398 - acc: 0.8297 - val_loss: 0.7939 - val_acc: 0.7083\n",
      "Epoch 6/10\n",
      "8847/8847 [==============================] - 132s 15ms/step - loss: 0.3607 - acc: 0.8637 - val_loss: 0.8321 - val_acc: 0.7022\n",
      "Epoch 7/10\n",
      "8847/8847 [==============================] - 128s 14ms/step - loss: 0.2625 - acc: 0.9071 - val_loss: 0.9636 - val_acc: 0.6911\n",
      "Epoch 8/10\n",
      "8847/8847 [==============================] - 128s 14ms/step - loss: 0.2113 - acc: 0.9246 - val_loss: 1.1507 - val_acc: 0.6911\n",
      "Epoch 9/10\n",
      "8847/8847 [==============================] - 129s 15ms/step - loss: 0.1514 - acc: 0.9492 - val_loss: 1.2572 - val_acc: 0.6982\n",
      "Epoch 10/10\n",
      "8847/8847 [==============================] - 129s 15ms/step - loss: 0.1141 - acc: 0.9615 - val_loss: 1.4220 - val_acc: 0.6880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec6c49ab70>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "model1.fit(x_train_pad, Y_encoded, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9831/9831 [==============================] - 33s 3ms/step\n",
      "CPU times: user 1min 45s, sys: 8.72 s, total: 1min 54s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model1.evaluate(x_test_pad, Y_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
